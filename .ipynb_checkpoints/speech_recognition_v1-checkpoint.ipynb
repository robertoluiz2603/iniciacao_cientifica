{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b0fde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 13:37:47.205999: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 13:37:47.575798: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-02 13:37:47.649179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-02 13:37:47.649193: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-02 13:37:48.661030: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 13:37:48.661097: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-02 13:37:48.661101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f6f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdbdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionarize_data (directory): #\"D:\\TIMIT\\TRAIN\" \"No linux é /media/roberto/UFD/TIMIT/TRAIN\"\n",
    "    data = {\"signal_path\" : [],\n",
    "            \"phn_path\" : [],\n",
    "            \"wrd_path\" : [],\n",
    "            \"txt_path\" : []}\n",
    "    for root, direc, file in os.walk(directory):\n",
    "            for i in file:            \n",
    "                ext = i.split('.')\n",
    "                file_path = os.path.join(root, ext[0])\n",
    "                wav = \"WAV\"\n",
    "                if ext[1] == wav:\n",
    "                    data[\"signal_path\"].append(file_path + \".WAV\")\n",
    "                    data[\"phn_path\"].append(file_path + \".PHN\")\n",
    "                    data[\"wrd_path\"].append(file_path + \".WRD\")\n",
    "                    data[\"txt_path\"].append(file_path + \".TXT\")\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843e4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_labels(lim_vec,label_vec,beg,end): #resolve o problema de intervalos inter-rotulos\n",
    "    i = 0\n",
    "    while i < len(lim_vec) and not(lim_vec[i][0] <= beg <= lim_vec[i][1]):\n",
    "        i+=1\n",
    "    j = 0\n",
    "    \n",
    "    while j < len(lim_vec) - 1 and not(lim_vec[j][0] <= end <= lim_vec[j][1]):\n",
    "        j+=1\n",
    "    return i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d5afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_melspectrogram(janelas_vec, sample_rate, nome, path_janela): #\"/home/roberto/iniciacao_cientifica/JANELAS\"\n",
    "    n_fft = 2048\n",
    "    janela = 512\n",
    "\n",
    "    #calcula a short term fourier transform:\n",
    "    stft = librosa.stft(janelas_vec, n_fft = n_fft, hop_length = janela)\n",
    "\n",
    "    #calcula o valor absoluto da stft (spectogram):\n",
    "    spectrogram = np.abs(stft)\n",
    "\n",
    "    #calcula o melspectrogram:\n",
    "    melspectrogram = librosa.feature.melspectrogram(y = janelas_vec, S = spectrogram ,sr = sample_rate, hop_length = janela, fmax = sample_rate/2)\n",
    "    file_name = str(nome) \n",
    "    os.chdir(path_janela)\n",
    "    diretorio = os.getcwd()\n",
    "    np.save(file_name,np.array(melspectrogram))\n",
    "    path = os.path.join(diretorio, file_name)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e70cf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(labels_vec, path): #\"/home/roberto/iniciacao_cientifica/ROTULOS\"\n",
    "    os.chdir(path) \n",
    "    np.save(\"rotulos.npy\",labels_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64e2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_signal(data,jan_path,label_path):   \n",
    "    #divide o sinal em intervalos de 100 ms (com passo de ms) da um rotulo -- caso o valor não exista, preencher com 0 até que de 100 ms\n",
    "    #prestar atenção à valores de intervalo que ficam entre dois (ou mais) rotulos\n",
    "    #copiar duas vezes e dar os dois (ou mais) rotulos\n",
    "    #fazer a transformada de fourier e tmb melspectrograma nessa função mesmo!!\n",
    "    janelas_vec = []\n",
    "    labels_vec = []\n",
    "    cont = 0\n",
    "    window_data = {\"window_path\": [],\n",
    "                   \"label\":[]}\n",
    "    result = \"resultado\"\n",
    "    \n",
    "    for values in data[\"phn_path\"]:\n",
    "        limites_vec = []\n",
    "        fonemas_vec = []\n",
    "        #carrega o arquivo .WAV do correspondente ao arquivo .PHN\n",
    "        path = values.split(\".\")\n",
    "        #print(path[0] + \".WAV\")\n",
    "        raw_signal, sample_rate = librosa.load(path[0] + \".WAV\", sr = 22050) #sr a definir\n",
    "\n",
    "        #permite a leitura do arquivo phn\n",
    "        read = open(values, \"r\")\n",
    "\n",
    "        #guarda em um vetor todas as linhas do arquivo .PHN\n",
    "        lines = read.readlines()\n",
    "\n",
    "        #define o valor limite que possui rótulos\n",
    "        lin = lines[-1].strip()\n",
    "        modules = lin.split(\" \")\n",
    "        limite_total = int(modules[1]) # após esse valor não existe mais rótulos\n",
    "\n",
    "        #copia o vetor do sinal extraido do .WAV do arquivo até o limite total\n",
    "        signal = raw_signal[:limite_total]\n",
    "\n",
    "        #adiciona todos os fonemas(rótulos) e seus intervalos em uma lista\n",
    "        for line in lines: \n",
    "            li = line.strip()\n",
    "            data_phonema = li.split(\" \")\n",
    "            lim_chao = int(data_phonema[0]) #limite por baixo\n",
    "            lim_teto = int(data_phonema[1]) #limite por cima\n",
    "            fonema = data_phonema[2]\n",
    "            limites = (lim_chao,lim_teto)\n",
    "            limites_vec.append(limites)\n",
    "            fonemas_vec.append(fonema)\n",
    "        cont_2 = 0\n",
    "        #separa o vetor em vetores menores (janelas copias)\n",
    "        for i in range(0, limite_total, int(sample_rate / 20)): \n",
    "            end = i + int(sample_rate/10)\n",
    "            \n",
    "            if end < limite_total:\n",
    "                janela = signal[i : end]\n",
    "            else:\n",
    "                janela = signal[i : limite_total-1]\n",
    "                \n",
    "            while len(janela) < (2**math.ceil(math.log(sample_rate/10, 2))): #se o tamanho do vetor for menor que a proxima potencia acima dele, adiciona 0 \n",
    "                janela = np.append(janela, 0)\n",
    "                \n",
    "            inicio, final = num_labels(limites_vec, labels_vec, i,end) #registra a primeira e a ultima ocorrencia da janela\n",
    "            \n",
    "            vers = 0\n",
    "            for j in range(inicio, final + 1):\n",
    "                jan = np.array(janela)\n",
    "                wind_path = save_melspectrogram(jan, sample_rate, (result +\"_s\"+str(cont) + \"_j\"+str(cont_2)+\"_v\"+str(vers)),jan_path)\n",
    "                os.chdir(direc)\n",
    "                window_data[\"window_path\"].append(wind_path)\n",
    "                window_data[\"label\"].append(fonemas_vec[j])\n",
    "                vers +=1\n",
    "            cont_2 += 1\n",
    "        cont += 1\n",
    "    save_labels(window_data[\"label\"],label_path)\n",
    "    os.chdir(direc)        \n",
    "    return window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb1b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path(path_janela, path_rotulo): #carrega os paths e rotulos das janelas já pré-processadas\n",
    "    janela_vec = []\n",
    "    for root, direc, file in os.walk(path_janela):\n",
    "        for i in file:\n",
    "            janela_vec.append(i)\n",
    "    rotulos_vec = np.load(path_rotulo)\n",
    "    return janela_vec, rotulos_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33270c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(vec, label):\n",
    "    for v in vec:\n",
    "        if v == label:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65bfb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_labels(window_dict):\n",
    "    lista_labels = []\n",
    "    for i in window_dict[\"label\"]:\n",
    "        if contains(lista_labels,i) == False:\n",
    "            lista_labels.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    return lista_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d28e9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_label(label):\n",
    "    if label in ['ae', 'ao', 'aa', 'ah']:\n",
    "        label = 'a'\n",
    "    elif label in ['eh', 'ey', 'iy', 'er']:\n",
    "        label = 'e'\n",
    "    elif label in ['ow', 'oy', 'aw', 'uw','axr']:\n",
    "        label = 'o'\n",
    "    elif label in ['ih', 'ay','ix']:\n",
    "        label = 'i'\n",
    "    elif label in ['uh', 'ux','uw']:\n",
    "        label = 'u'\n",
    "    else:\n",
    "        label = 'consonant'\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3c63e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_lista(lista):\n",
    "    resultado = []\n",
    "    for i in lista:\n",
    "        label = classifica_label(i)\n",
    "        resultado.append(label)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74faf5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_window, train_label = load_from_path(\"/home/roberto/iniciacao_cientifica/JANELAS\",\"/home/roberto/iniciacao_cientifica/ROTULOS/rotulos.npy\")\n",
    "window_dict= {\"window_path\": [],\n",
    "                   \"label\":[]}\n",
    "window_dict[\"window_path\"] = train_window[:]\n",
    "window_dict[\"label\"] = train_label[:]\n",
    "train_classified_labels = classifica_lista(window_dict[\"label\"])\n",
    "window_dict[\"label\"] = train_classified_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adecff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = exclui_consoantes(window_dict)\n",
    "window_dict = dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e9b584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_window, test_label = load_from_path(\"/home/roberto/iniciacao_cientifica/JANELAS_TESTE\",\"/home/roberto/iniciacao_cientifica/ROTULOS_TESTE/rotulos.npy\")\n",
    "window_dict_test = {\"window_path\": [],\n",
    "                   \"label\":[]}\n",
    "window_dict_test[\"window_path\"] = test_window[:]\n",
    "window_dict_test[\"label\"] = test_label[:]\n",
    "test_classified_labels = classifica_lista(window_dict_test[\"label\"])\n",
    "window_dict_test[\"label\"] = test_classified_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac743747",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test = exclui_consoantes(window_dict_test)\n",
    "window_dict_test = dict_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6333bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(labels):\n",
    "    vec = []\n",
    "    contador = 0\n",
    "    for i in labels:\n",
    "        if not contains(vec,i):\n",
    "            vec.append(i)\n",
    "            contador += 1\n",
    "    print(vec)\n",
    "    return contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c241ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixels(data):\n",
    "    #pixels ficam entre 0 e 1\n",
    "    data = data.astype('float32')/255.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de2ad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_labels(label):\n",
    "    label = pd.get_dummies(label)\n",
    "    return label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bea6d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclui_consoantes(window_dict):\n",
    "    window_data = {\"window_path\": [],\n",
    "                   \"label\":[]}\n",
    "    contador = 0\n",
    "    for i in window_dict[\"label\"]:\n",
    "        if i != \"consonant\":\n",
    "            window_data[\"window_path\"].append(window_dict[\"window_path\"][contador])\n",
    "            window_data[\"label\"].append(window_dict[\"label\"][contador])\n",
    "        contador += 1\n",
    "    return window_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea58adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(window_data, path):\n",
    "    t_data = np.array(window_data[\"window_path\"])\n",
    "    train_data = []\n",
    "    for t in t_data:\n",
    "        train_data.append(np.load(path+\"/\"+t))\n",
    "    train_data = np.array(train_data)\n",
    "    train_label = window_data[\"label\"]\n",
    "    return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00f10a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = models.Sequential()\n",
    "    # network layers:\n",
    "    network.add(layers.Conv1D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform', input_shape=(128, 9)))\n",
    "    network.add(layers.Conv1D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Conv1D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.Conv1D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Conv1D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.Conv1D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Flatten())\n",
    "    network.add(layers.Dense(128, activation='relu'))\n",
    "    network.add(layers.Dense(5, activation='softmax'))\n",
    "    # network configurations (optimizer, loss and metrics functions):\n",
    "    network.compile(optimizer='RMSprop',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0df48f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 13:38:37.099338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-02 13:38:37.099736: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-02 13:38:37.099749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (roberto-Inspiron-15-3511): /proc/driver/nvidia/version does not exist\n",
      "2023-03-02 13:38:37.101777: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1437/1437 [==============================] - 30s 20ms/step - loss: 1.4847 - accuracy: 0.2775\n",
      "Epoch 2/5\n",
      "1437/1437 [==============================] - 31s 21ms/step - loss: 1.4830 - accuracy: 0.2806\n",
      "Epoch 3/5\n",
      "1437/1437 [==============================] - 42s 29ms/step - loss: 1.4827 - accuracy: 0.2816\n",
      "Epoch 4/5\n",
      "1437/1437 [==============================] - 59s 41ms/step - loss: 1.4826 - accuracy: 0.2817\n",
      "Epoch 5/5\n",
      "1437/1437 [==============================] - 61s 42ms/step - loss: 1.4826 - accuracy: 0.2824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40d557d060>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_label = load_data(window_dict, \"/home/roberto/iniciacao_cientifica/JANELAS\")\n",
    "train_data = normalize_pixels(train_data)\n",
    "train_label = categorize_labels(train_label)\n",
    "\n",
    "network = create_network()\n",
    "network.fit(train_data, train_label, epochs = 5, batch_size = 128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81a87c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2091/2091 [==============================] - 16s 7ms/step - loss: 1.4760 - accuracy: 0.2949\n",
      "Test loss: 1.4760438203811646\n",
      "Test accuracy: 0.29488980770111084\n"
     ]
    }
   ],
   "source": [
    "test_data, test_label = load_data(window_dict_test, \"/home/roberto/iniciacao_cientifica/JANELAS_TESTE\")\n",
    "test_data = normalize_pixels(test_data)\n",
    "test_label = categorize_labels(test_label)\n",
    "\n",
    "loss, accuracy = network.evaluate(test_data, test_label)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
