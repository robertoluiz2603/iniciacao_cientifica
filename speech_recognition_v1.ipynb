{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0b0fde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 11:33:23.084136: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-26 11:33:23.471870: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-26 11:33:23.554977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-26 11:33:23.555001: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-26 11:33:24.527556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-26 11:33:24.527609: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-26 11:33:24.527613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f6f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdbdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionarize_data (directory): #\"D:\\TIMIT\\TRAIN\" \"No linux é /media/roberto/UFD/TIMIT/TRAIN\"\n",
    "    data = {\"signal_path\" : [],\n",
    "            \"phn_path\" : [],\n",
    "            \"wrd_path\" : [],\n",
    "            \"txt_path\" : []}\n",
    "    for root, direc, file in os.walk(directory):\n",
    "            for i in file:            \n",
    "                ext = i.split('.')\n",
    "                file_path = os.path.join(root, ext[0])\n",
    "                wav = \"WAV\"\n",
    "                if ext[1] == wav:\n",
    "                    data[\"signal_path\"].append(file_path + \".WAV\")\n",
    "                    data[\"phn_path\"].append(file_path + \".PHN\")\n",
    "                    data[\"wrd_path\"].append(file_path + \".WRD\")\n",
    "                    data[\"txt_path\"].append(file_path + \".TXT\")\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843e4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_labels(lim_vec,label_vec,beg,end): #resolve o problema de intervalos inter-rotulos\n",
    "    i = 0\n",
    "    while i < len(lim_vec) and not(lim_vec[i][0] <= beg <= lim_vec[i][1]):\n",
    "        i+=1\n",
    "    j = 0\n",
    "    \n",
    "    while j < len(lim_vec) - 1 and not(lim_vec[j][0] <= end <= lim_vec[j][1]):\n",
    "        j+=1\n",
    "    return i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2d5afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_melspectrogram(janelas_vec, sample_rate, nome, path_janela): #\"/home/roberto/iniciacao_cientifica/JANELAS\"\n",
    "    n_fft = 2048\n",
    "    janela = 512\n",
    "\n",
    "    #calcula a short term fourier transform:\n",
    "    stft = librosa.stft(janelas_vec, n_fft = n_fft, hop_length = janela)\n",
    "\n",
    "    #calcula o valor absoluto da stft (spectogram):\n",
    "    spectrogram = np.abs(stft)\n",
    "\n",
    "    #calcula o melspectrogram:\n",
    "    melspectrogram = librosa.feature.melspectrogram(y = janelas_vec, S = spectrogram ,sr = sample_rate, hop_length = janela, fmax = sample_rate/2)\n",
    "    file_name = str(nome) \n",
    "    os.chdir(path_janela)\n",
    "    diretorio = os.getcwd()\n",
    "    np.save(file_name,np.array(melspectrogram))\n",
    "    path = os.path.join(diretorio, file_name)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e70cf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(labels_vec, path): #\"/home/roberto/iniciacao_cientifica/ROTULOS\"\n",
    "    os.chdir(path) \n",
    "    np.save(\"rotulos.npy\",labels_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d64e2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_signal(data,jan_path,label_path):   \n",
    "    #divide o sinal em intervalos de 100 ms (com passo de ms) da um rotulo -- caso o valor não exista, preencher com 0 até que de 100 ms\n",
    "    #prestar atenção à valores de intervalo que ficam entre dois (ou mais) rotulos\n",
    "    #copiar duas vezes e dar os dois (ou mais) rotulos\n",
    "    #fazer a transformada de fourier e tmb melspectrograma nessa função mesmo!!\n",
    "    janelas_vec = []\n",
    "    labels_vec = []\n",
    "    cont = 0\n",
    "    window_data = {\"window_path\": [],\n",
    "                   \"label\":[]}\n",
    "    result = \"resultado\"\n",
    "    \n",
    "    for values in data[\"phn_path\"]:\n",
    "        limites_vec = []\n",
    "        fonemas_vec = []\n",
    "        #carrega o arquivo .WAV do correspondente ao arquivo .PHN\n",
    "        path = values.split(\".\")\n",
    "        #print(path[0] + \".WAV\")\n",
    "        raw_signal, sample_rate = librosa.load(path[0] + \".WAV\", sr = 22050) #sr a definir\n",
    "\n",
    "        #permite a leitura do arquivo phn\n",
    "        read = open(values, \"r\")\n",
    "\n",
    "        #guarda em um vetor todas as linhas do arquivo .PHN\n",
    "        lines = read.readlines()\n",
    "\n",
    "        #define o valor limite que possui rótulos\n",
    "        lin = lines[-1].strip()\n",
    "        modules = lin.split(\" \")\n",
    "        limite_total = int(modules[1]) # após esse valor não existe mais rótulos\n",
    "\n",
    "        #copia o vetor do sinal extraido do .WAV do arquivo até o limite total\n",
    "        signal = raw_signal[:limite_total]\n",
    "\n",
    "        #adiciona todos os fonemas(rótulos) e seus intervalos em uma lista\n",
    "        for line in lines: \n",
    "            li = line.strip()\n",
    "            data_phonema = li.split(\" \")\n",
    "            lim_chao = int(data_phonema[0]) #limite por baixo\n",
    "            lim_teto = int(data_phonema[1]) #limite por cima\n",
    "            fonema = data_phonema[2]\n",
    "            limites = (lim_chao,lim_teto)\n",
    "            limites_vec.append(limites)\n",
    "            fonemas_vec.append(fonema)\n",
    "        cont_2 = 0\n",
    "        #separa o vetor em vetores menores (janelas copias)\n",
    "        for i in range(0, limite_total, int(sample_rate / 20)): \n",
    "            end = i + int(sample_rate/10)\n",
    "            \n",
    "            if end < limite_total:\n",
    "                janela = signal[i : end]\n",
    "            else:\n",
    "                janela = signal[i : limite_total-1]\n",
    "                \n",
    "            while len(janela) < (2**math.ceil(math.log(sample_rate/10, 2))): #se o tamanho do vetor for menor que a proxima potencia acima dele, adiciona 0 \n",
    "                janela = np.append(janela, 0)\n",
    "                \n",
    "            inicio, final = num_labels(limites_vec, labels_vec, i,end) #registra a primeira e a ultima ocorrencia da janela\n",
    "            \n",
    "            vers = 0\n",
    "            for j in range(inicio, final + 1):\n",
    "                jan = np.array(janela)\n",
    "                wind_path = save_melspectrogram(jan, sample_rate, (result +\"_s\"+str(cont) + \"_j\"+str(cont_2)+\"_v\"+str(vers)),jan_path)\n",
    "                os.chdir(direc)\n",
    "                window_data[\"window_path\"].append(wind_path)\n",
    "                window_data[\"label\"].append(fonemas_vec[j])\n",
    "                vers +=1\n",
    "            cont_2 += 1\n",
    "        cont += 1\n",
    "    save_labels(window_data[\"label\"],label_path)\n",
    "    os.chdir(direc)        \n",
    "    return window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fb1b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_path(path_janela, path_rotulo): #carrega os paths e rotulos das janelas já pré-processadas\n",
    "    janela_vec = []\n",
    "    for root, direc, file in os.walk(path_janela):\n",
    "        for i in file:\n",
    "            janela_vec.append(i)\n",
    "    rotulos_vec = np.load(path_rotulo)\n",
    "    return janela_vec, rotulos_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bffa821a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_test \u001b[38;5;241m=\u001b[39m dictionarize_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/roberto/UFD/TIMIT/TEST\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m window_data_test \u001b[38;5;241m=\u001b[39m \u001b[43mdivide_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/roberto/iniciacao_cientifica/JANELAS_TESTE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/roberto/iniciacao_cientifica/ROTULOS_TESTE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 56\u001b[0m, in \u001b[0;36mdivide_signal\u001b[0;34m(data, jan_path, label_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m     janela \u001b[38;5;241m=\u001b[39m signal[i : limite_total\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(janela) \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmath\u001b[38;5;241m.\u001b[39mceil(math\u001b[38;5;241m.\u001b[39mlog(sample_rate\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m2\u001b[39m))): \u001b[38;5;66;03m#se o tamanho do vetor for menor que a proxima potencia acima dele, adiciona 0 \u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     janela \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjanela\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m inicio, final \u001b[38;5;241m=\u001b[39m num_labels(limites_vec, labels_vec, i,end) \u001b[38;5;66;03m#registra a primeira e a ultima ocorrencia da janela\u001b[39;00m\n\u001b[1;32m     60\u001b[0m vers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:5442\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   5441\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m-> 5442\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5443\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate((arr, values), axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mravel\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:1859\u001b[0m, in \u001b[0;36mravel\u001b[0;34m(a, order)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asarray(a)\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_test = dictionarize_data(\"/media/roberto/UFD/TIMIT/TEST\")\n",
    "window_data_test = divide_signal(data_test,\"/home/roberto/iniciacao_cientifica/JANELAS_TESTE\",\"/home/roberto/iniciacao_cientifica/ROTULOS_TESTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74faf5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553005\n",
      "553005\n"
     ]
    }
   ],
   "source": [
    "train_window, train_label = load_from_path(\"/home/roberto/iniciacao_cientifica/JANELAS\",\"/home/roberto/iniciacao_cientifica/ROTULOS/rotulos.npy\")\n",
    "window_dict= {\"window_path\": [],\n",
    "                   \"label\":[]}\n",
    "window_dict[\"window_path\"] = train_window[:]\n",
    "window_dict[\"label\"] = train_label[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e351cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "vec = np.load(\"/home/roberto/iniciacao_cientifica/ROTULOS_TESTE/rotulos.npy\")\n",
    "print(len(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33270c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(vec, label):\n",
    "    for v in vec:\n",
    "        if v == label:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65bfb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_labels = []\n",
    "for i in window_dict[\"label\"]:\n",
    "    if contains(lista_labels,i) == False:\n",
    "        lista_labels.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d28e9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_label(label):\n",
    "    if label in ['ae', 'ao', 'aa', 'ah']:\n",
    "        label = 'a'\n",
    "    elif label in ['eh', 'ey', 'iy', 'er']:\n",
    "        label = 'e'\n",
    "    elif label in ['ow', 'oy', 'aw', 'uw']:\n",
    "        label = 'o'\n",
    "    elif label in ['ih', 'ay']:\n",
    "        label = 'i'\n",
    "    elif label in ['uh', 'ux']:\n",
    "        label = 'u'\n",
    "    else:\n",
    "        label = 'consonant'\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3c63e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_lista(lista):\n",
    "    resultado = []\n",
    "    for i in lista:\n",
    "        label = classifica_label(i)\n",
    "        resultado.append(label)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90663d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_dict[\"label\"] = classifica_lista(window_dict[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf949ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_label = []\n",
    "for i in window_dict[\"label\"]:\n",
    "    if contains(lista_label,i) == False:\n",
    "        lista_label.append(i)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6333bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(labels):\n",
    "    vec = []\n",
    "    contador = 0\n",
    "    for i in labels:\n",
    "        if not contains(vec,i):\n",
    "            vec.append(i)\n",
    "            contador += 1\n",
    "    print(vec)\n",
    "    return contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c241ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixels(data):\n",
    "    #pixels ficam entre 0 e 1\n",
    "    data = data.astype('float32')/255.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de2ad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_labels(label):\n",
    "    label = pd.get_dummies(label)\n",
    "    return label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea58adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(window_data):\n",
    "    t_data = np.array(window_data[\"window_path\"])\n",
    "    train_data = []\n",
    "    for t in t_data:\n",
    "        train_data.append(np.load(t+'.npy'))\n",
    "    train_data = np.array(train_data)\n",
    "    train_label = window_data[\"label\"]\n",
    "    return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00f10a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = models.Sequential()\n",
    "    # network layers:\n",
    "    network.add(layers.Conv1D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform', input_shape=(128, 9)))\n",
    "    network.add(layers.Conv1D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Conv1D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.Conv1D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Conv1D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.Conv1D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Flatten())\n",
    "    network.add(layers.Dense(128, activation='relu'))\n",
    "    network.add(layers.Dense(6, activation='softmax'))\n",
    "    # network configurations (optimizer, loss and metrics functions):\n",
    "    network.compile(optimizer='RMSprop',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0df48f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 21:44:21.228103: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-25 21:44:21.230169: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-25 21:44:21.231332: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (roberto-Inspiron-15-3511): /proc/driver/nvidia/version does not exist\n",
      "2023-02-25 21:44:21.252659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4321/4321 [==============================] - 77s 18ms/step - loss: 0.9755 - accuracy: 0.7299\n",
      "Epoch 2/5\n",
      "4321/4321 [==============================] - 78s 18ms/step - loss: 0.9726 - accuracy: 0.7300\n",
      "Epoch 3/5\n",
      "4321/4321 [==============================] - 78s 18ms/step - loss: 0.9720 - accuracy: 0.7300\n",
      "Epoch 4/5\n",
      "4321/4321 [==============================] - 77s 18ms/step - loss: 0.9717 - accuracy: 0.7300\n",
      "Epoch 5/5\n",
      "4321/4321 [==============================] - 77s 18ms/step - loss: 0.9717 - accuracy: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e7ab85300>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_label = load_data(window_dict)\n",
    "train_data = normalize_pixels(train_data)\n",
    "train_label = categorize_labels(train_label)\n",
    "network = create_network()\n",
    "network.fit(train_data, train_label, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_set, l_set = load_data(window_dict)\n",
    "os.chdir(\"C://Users//rober//UTFPR//machine_learning//janelas_certas\")\n",
    "diretorio = os.getcwd()\n",
    "np.save('resultados',t_set)\n",
    "os.chdir(\"C://Users//rober//UTFPR//machine_learning//rotulos\")\n",
    "diretorio = os.getcwd()\n",
    "np.save('rotulos', l_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea445002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users//rober//UTFPR//machine_learning//janelas_certas//resultados.npy\n"
     ]
    }
   ],
   "source": [
    "direc = \"C://Users//rober//UTFPR//machine_learning//janelas_certas\"\n",
    "for i in os.listdir(direc):\n",
    "    path_npy = direc+\"//\"+i\n",
    "    print(path_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ccd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_janelas(npy_path):\n",
    "    janelas = np.load(npy_path)\n",
    "    return janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "585ef03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    labels = np.load(label_path)\n",
    "    return labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
