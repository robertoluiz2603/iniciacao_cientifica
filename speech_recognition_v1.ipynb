{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b0fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68f6f6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/roberto/iniciacao_cientifica\n"
     ]
    }
   ],
   "source": [
    "direc = os.getcwd()\n",
    "print (direc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcdbdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionarize_data (directory): #\"D:\\TIMIT\\TRAIN\" \"No linux é /media/roberto/UFD/TIMIT/TRAIN\"\n",
    "    data = {\"signal_path\" : [],\n",
    "            \"phn_path\" : [],\n",
    "            \"wrd_path\" : [],\n",
    "            \"txt_path\" : []}\n",
    "    for root, direc, file in os.walk(directory):\n",
    "            for i in file:            \n",
    "                ext = i.split('.')\n",
    "                file_path = os.path.join(root, ext[0])\n",
    "                wav = \"WAV\"\n",
    "                if ext[1] == wav:\n",
    "                    data[\"signal_path\"].append(file_path + \".WAV\")\n",
    "                    data[\"phn_path\"].append(file_path + \".PHN\")\n",
    "                    data[\"wrd_path\"].append(file_path + \".WRD\")\n",
    "                    data[\"txt_path\"].append(file_path + \".TXT\")\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "843e4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_labels(lim_vec,label_vec,beg,end): #resolve o problema de intervalos inter-rotulos\n",
    "    i = 0\n",
    "    while i < len(lim_vec) and not(lim_vec[i][0] <= beg <= lim_vec[i][1]):\n",
    "        i+=1\n",
    "    j = 0\n",
    "    \n",
    "    while j < len(lim_vec) - 1 and not(lim_vec[j][0] <= end <= lim_vec[j][1]):\n",
    "        j+=1\n",
    "    return i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2d5afa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_melspectrogram(janelas_vec, sample_rate , nome):\n",
    "    n_fft = 2048\n",
    "    janela = 512\n",
    "\n",
    "    #calcula a short term fourier transform:\n",
    "    #stft = librosa.stft(janelas_vec, n_fft = n_fft, hop_length = janela)\n",
    "\n",
    "    #calcula o valor absoluto da stft (spectogram):\n",
    "    #spectrogram = np.abs(stft)\n",
    "\n",
    "    #calcula o melspectrogram:\n",
    "    #melspectrogram = librosa.feature.melspectrogram(y = janelas_vec, S = spectrogram ,sr = sample_rate, hop_length = janela, fmax = sample_rate/2)\n",
    "    file_name = str(nome) \n",
    "    os.chdir(\"/home/roberto/iniciacao_cientifica/JANELAS\")\n",
    "    diretorio = os.getcwd()\n",
    "    #np.save(file_name,np.array(melspectrogram))\n",
    "    path = os.path.join(diretorio, file_name)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70cf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(labels_vec):\n",
    "    os.chdir(\"/home/roberto/iniciacao_cientifica/ROTULOS\") #/media/roberto/UFD/TIMIT/TRAIN \"D:\\TIMIT\\LABELS\"\n",
    "    np.save(\"rotulos.npy\",labels_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64e2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_signal(data):   \n",
    "    #divide o sinal em intervalos de 100 ms (com passo de ms) da um rotulo -- caso o valor não exista, preencher com 0 até que de 100 ms\n",
    "    #prestar atenção à valores de intervalo que ficam entre dois (ou mais) rotulos\n",
    "    #copiar duas vezes e dar os dois (ou mais) rotulos\n",
    "    #fazer a transformada de fourier e tmb melspectrograma nessa função mesmo!!\n",
    "    janelas_vec = []\n",
    "    labels_vec = []\n",
    "    cont = 0\n",
    "    window_data = {\"window_path\": [],\n",
    "                   \"label\":[]}\n",
    "    result = \"resultado\"\n",
    "    for values in data[\"phn_path\"]:\n",
    "        limites_vec = []\n",
    "        fonemas_vec = []\n",
    "        #carrega o arquivo .WAV do correspondente ao arquivo .PHN\n",
    "        path = values.split(\".\")\n",
    "        #print(path[0] + \".WAV\")\n",
    "        raw_signal, sample_rate = librosa.load(path[0] + \".WAV\", sr = 22050) #sr a definir\n",
    "\n",
    "        #permite a leitura do arquivo phn\n",
    "        read = open(values, \"r\")\n",
    "\n",
    "        #guarda em um vetor todas as linhas do arquivo .PHN\n",
    "        lines = read.readlines()\n",
    "\n",
    "        #define o valor limite que possui rótulos\n",
    "        lin = lines[-1].strip()\n",
    "        modules = lin.split(\" \")\n",
    "        limite_total = int(modules[1]) # após esse valor não existe mais rótulos\n",
    "\n",
    "        #copia o vetor do sinal extraido do .WAV do arquivo até o limite total\n",
    "        signal = raw_signal[:limite_total]\n",
    "\n",
    "        #adiciona todos os fonemas(rótulos) e seus intervalos em uma lista\n",
    "        for line in lines: \n",
    "            li = line.strip()\n",
    "            data_phonema = li.split(\" \")\n",
    "            lim_chao = int(data_phonema[0]) #limite por baixo\n",
    "            lim_teto = int(data_phonema[1]) #limite por cima\n",
    "            fonema = data_phonema[2]\n",
    "            limites = (lim_chao,lim_teto)\n",
    "            limites_vec.append(limites)\n",
    "            fonemas_vec.append(fonema)\n",
    "        cont_2 = 0\n",
    "        #separa o vetor em vetores menores (janelas copias)\n",
    "        for i in range(0, limite_total, int(sample_rate / 20)): \n",
    "            end = i + int(sample_rate/10)\n",
    "            \n",
    "            if end < limite_total:\n",
    "                janela = signal[i : end]\n",
    "            else:\n",
    "                janela = signal[i : limite_total-1]\n",
    "                \n",
    "            while len(janela) < (2**math.ceil(math.log(sample_rate/10, 2))): #se o tamanho do vetor for menor que a proxima potencia acima dele, adiciona 0 \n",
    "                janela = np.append(janela, 0)\n",
    "                \n",
    "            inicio, final = num_labels(limites_vec, labels_vec, i,end) #registra a primeira e a ultima ocorrencia da janela\n",
    "            \n",
    "            vers = 0\n",
    "            for j in range(inicio, final + 1):\n",
    "                jan = np.array(janela)\n",
    "                wind_path = save_melspectrogram(jan, sample_rate, (result +\"_s\"+str(cont) + \"_j\"+str(cont_2)+\"_v\"+str(vers)))\n",
    "                os.chdir(direc)\n",
    "                window_data[\"window_path\"].append(wind_path)\n",
    "                window_data[\"label\"].append(fonemas_vec[j])\n",
    "                vers +=1\n",
    "            cont_2 += 1\n",
    "        cont += 1\n",
    "    save_labels(window_data[\"label\"])\n",
    "    os.chdir(direc)        \n",
    "    return window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c74faf5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = dictionarize_data(\"/media/roberto/UFD/TIMIT/TRAIN\") #/media/roberto/UFD/TIMIT/TRAIN #\"D://TIMIT//TRAIN\"\n",
    "window_dict = divide_signal(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33270c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(vec, label):\n",
    "    for v in vec:\n",
    "        if v == label:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65bfb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_labels = []\n",
    "for i in window_dict[\"label\"]:\n",
    "    if contains(lista_labels,i) == False:\n",
    "        lista_labels.append(i)\n",
    "    else:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d28e9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_label(label):\n",
    "    if label in ['ae', 'ao', 'aa', 'ah']:\n",
    "        label = 'a'\n",
    "    elif label in ['eh', 'ey', 'iy', 'er']:\n",
    "        label = 'e'\n",
    "    elif label in ['ow', 'oy', 'aw', 'uw']:\n",
    "        label = 'o'\n",
    "    elif label in ['ih', 'ay']:\n",
    "        label = 'i'\n",
    "    elif label in ['uh', 'ux']:\n",
    "        label = 'u'\n",
    "    else:\n",
    "        label = 'consonant'\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3c63e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifica_lista(lista):\n",
    "    resultado = []\n",
    "    for i in lista:\n",
    "        label = classifica_label(i)\n",
    "        resultado.append(label)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90663d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_dict[\"label\"] = classifica_lista(window_dict[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf949ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_label = []\n",
    "for i in window_dict[\"label\"]:\n",
    "    if contains(lista_label,i) == False:\n",
    "        lista_label.append(i)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6333bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(labels):\n",
    "    vec = []\n",
    "    contador = 0\n",
    "    for i in labels:\n",
    "        if not contains(vec,i):\n",
    "            vec.append(i)\n",
    "            contador += 1\n",
    "    print(vec)\n",
    "    return contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c241ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pixels(data):\n",
    "    #pixels ficam entre 0 e 1\n",
    "    data = data.astype('float32')/255.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de2ad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_labels(label):\n",
    "    label = pd.get_dummies(label)\n",
    "    return label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea58adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(window_data):\n",
    "    t_data = np.array(window_data[\"window_path\"])\n",
    "    train_data = []\n",
    "    for t in t_data:\n",
    "        train_data.append(np.load(t+'.npy'))\n",
    "    train_data = np.array(train_data)\n",
    "    train_label = window_data[\"label\"]\n",
    "    return train_data, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "00f10a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = models.Sequential()\n",
    "    # network layers:\n",
    "    network.add(layers.Conv1D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform', input_shape=(128, 9)))\n",
    "    network.add(layers.Conv1D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Conv1D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.Conv1D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Conv1D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.Conv1D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
    "    network.add(layers.MaxPooling1D(2))\n",
    "    network.add(layers.Flatten())\n",
    "    network.add(layers.Dense(128, activation='relu'))\n",
    "    network.add(layers.Dense(6, activation='softmax'))\n",
    "    # network configurations (optimizer, loss and metrics functions):\n",
    "    network.compile(optimizer='RMSprop',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df48f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = load_data(window_dict)\n",
    "train_data = normalize_pixels(train_data)\n",
    "train_label = categorize_labels(train_label)\n",
    "network = create_network()\n",
    "network.fit(train_data, train_label, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_set, l_set = load_data(window_dict)\n",
    "os.chdir(\"C://Users//rober//UTFPR//machine_learning//janelas_certas\")\n",
    "diretorio = os.getcwd()\n",
    "np.save('resultados',t_set)\n",
    "os.chdir(\"C://Users//rober//UTFPR//machine_learning//rotulos\")\n",
    "diretorio = os.getcwd()\n",
    "np.save('rotulos', l_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea445002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users//rober//UTFPR//machine_learning//janelas_certas//resultados.npy\n"
     ]
    }
   ],
   "source": [
    "direc = \"C://Users//rober//UTFPR//machine_learning//janelas_certas\"\n",
    "for i in os.listdir(direc):\n",
    "    path_npy = direc+\"//\"+i\n",
    "    print(path_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ccd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_janelas(npy_path):\n",
    "    janelas = np.load(npy_path)\n",
    "    return janelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "585ef03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_path):\n",
    "    labels = np.load(label_path)\n",
    "    return labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
